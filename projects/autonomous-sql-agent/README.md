# ğŸ¤– Autonomous SQL Agent

A production-ready autonomous agent that translates natural language questions into SQL queries and executes them on SQLite databases. Built with fine-tuned Qwen 2.5-1.5B model using QLoRA technique.

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—%20Transformers-4.30+-yellow.svg)](https://huggingface.co/docs/transformers/index)

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Project Structure](#-project-structure)
- [Database Setup](#-database-setup)
- [Usage](#-usage)
- [Testing](#-testing)
- [Development](#-development)
- [Technical Details](#-technical-details)
- [Contributing](#-contributing)

## ğŸ¯ Overview

The Autonomous SQL Agent is an intelligent system that bridges the gap between natural language and SQL databases. It leverages a fine-tuned Qwen 2.5-1.5B model to understand user questions and convert them into accurate SQL queries, then executes these queries autonomously on SQLite databases.

### Key Capabilities
- **Natural Language Understanding**: Processes complex user questions about data
- **SQL Generation**: Converts questions into syntactically correct SQL queries
- **Autonomous Execution**: Runs queries and returns formatted results
- **Multiple Interfaces**: CLI and web-based interfaces for different use cases
- **Production Ready**: Includes training scripts, evaluation tools, and deployment guides

## âœ¨ Features

- **ğŸ”„ Text-to-SQL Translation**: Advanced NLP model translates natural language to SQL
- **ğŸ§  Autonomous Workflow**: Complete question-to-answer pipeline
- **ğŸ›ï¸ Multiple Interfaces**: Command-line and web-based user interfaces
- **ğŸ“Š Real-time Execution**: Immediate query execution and result display
- **ğŸ”§ Fine-tuned Model**: Optimized for SQL generation tasks using QLoRA
- **ğŸš€ Production Ready**: Includes training, evaluation, and deployment scripts

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Input    â”‚â”€â”€â”€â–¶â”‚  SQL Generation  â”‚â”€â”€â”€â–¶â”‚  Query Executionâ”‚
â”‚  (Natural Lang) â”‚    â”‚   (Qwen 2.5B)    â”‚    â”‚   (SQLite)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Result Format  â”‚
                       â”‚   & Display      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

1. **Model Layer**: Fine-tuned Qwen 2.5-1.5B with QLoRA adapters
2. **Processing Layer**: SQL generation and validation
3. **Database Layer**: SQLite connection and query execution
4. **Interface Layer**: CLI and web-based user interfaces

## ğŸ”§ Installation

### Prerequisites

- **Python 3.8+**
- **CUDA-capable GPU** (for training, optional for inference)
- **8GB+ RAM** (16GB recommended for model loading)

### Environment Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd autonomous-sql-agent
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   # Main dependencies
   pip install -r requirements.txt
   
   # Demo dependencies (if using web interface)
   pip install -r demo/requirements.txt
   ```

### System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| RAM | 8GB | 16GB+ |
| Storage | 10GB | 20GB+ |
| GPU | None (CPU) | NVIDIA GPU with 8GB+ VRAM |
| Python | 3.8+ | 3.9+ |

## ğŸ“ Project Structure

```
autonomous-sql-agent/
â”œâ”€â”€ agent/                     # Core agent implementation
â”‚   â””â”€â”€ run_agent.py          # Command-line interface agent
â”œâ”€â”€ data/                     # Database files and schemas
â”‚   â””â”€â”€ README.md            # Data directory documentation
â”œâ”€â”€ demo/                     # Web demonstration
â”‚   â”œâ”€â”€ app.py               # Gradio web application
â”‚   â””â”€â”€ requirements.txt     # Demo-specific dependencies
â”œâ”€â”€ notebooks/                # Training and evaluation notebooks
â”‚   â”œâ”€â”€ SQL_Assistant_Production.ipynb
â”‚   â””â”€â”€ sql_assistant.ipynb
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ deploy.py            # Deployment automation
â”‚   â”œâ”€â”€ evaluate.py          # Model evaluation tools
â”‚   â”œâ”€â”€ setup_db.py          # Database initialization
â”‚   â””â”€â”€ train.py             # Model training script
â”œâ”€â”€ requirements.txt          # Main project dependencies
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ .gitignore               # Git ignore rules
```

### File Dependencies

- **`agent/run_agent.py`**: Depends on `data/dummy_database.db` (created by `scripts/setup_db.py`)
- **`demo/app.py`**: Standalone with embedded database creation
- **`scripts/setup_db.py`**: Creates database schema and sample data
- **Training notebooks**: Require model files and datasets (not included)

## ğŸ—„ï¸ Database Setup

### Quick Start Database

The project includes a pre-configured SQLite database with sample employee data:

```python
# Initialize database
python scripts/setup_db.py

# Database schema:
employees (
    id INTEGER PRIMARY KEY,
    name TEXT,
    department TEXT,
    salary INTEGER,
    hire_date DATE
)
```

### Sample Data

The dummy database includes 5 employee records across different departments:

| ID | Name | Department | Salary | Hire Date |
|----|------|------------|--------|-----------|
| 1 | Alice Smith | Sales | 55,000 | 2021-01-15 |
| 2 | Bob Jones | Engineering | 85,000 | 2020-03-10 |
| 3 | Charlie Brown | Sales | 48,000 | 2022-06-23 |
| 4 | Diana Prince | Engineering | 92,000 | 2019-11-05 |
| 5 | Evan Wright | HR | 45,000 | 2021-09-30 |

## ğŸš€ Usage

### Command-Line Interface

1. **Setup the database** (first time only)
   ```bash
   python scripts/setup_db.py
   ```

2. **Run the agent**
   ```bash
   python agent/run_agent.py --adapter <your-hf-model-id>
   ```

3. **Interactive session**
   ```
   âœ… Agent bereit! Tippe 'exit' zum Beenden.

   Deine Frage an die Datenbank: Who works in Sales?
   ğŸ§  Gedanke (SQL): SELECT name FROM employees WHERE department = 'Sales';
   ğŸ“Š Ergebnis aus DB: [('Alice Smith',), ('Charlie Brown',)]
   ```

### Web Demo Interface

1. **Install demo dependencies**
   ```bash
   pip install -r demo/requirements.txt
   ```

2. **Launch the web interface**
   ```bash
   python demo/app.py
   ```

3. **Access the demo**
   - Open browser to the provided local URL (typically `http://localhost:7860`)
   - Try example queries:
     - "Show me all employees in Sales"
     - "Who earns the most?"
     - "Count employees in Engineering"

### Example Queries

| Natural Language Question | Generated SQL |
|---------------------------|---------------|
| "Who works in Sales?" | `SELECT name FROM employees WHERE department = 'Sales';` |
| "Show me employees earning more than 80000" | `SELECT name, salary FROM employees WHERE salary > 80000;` |
| "What's the average salary by department?" | `SELECT department, AVG(salary) FROM employees GROUP BY department;` |

## ğŸ§ª Testing

### Unit Testing

1. **Database connectivity**
   ```bash
   python scripts/setup_db.py  # Should create database successfully
   ```

2. **Model loading**
   ```bash
   python -c "
   from transformers import AutoTokenizer, AutoModelForCausalLM
   from peft import PeftModel
   # Test basic model loading
   "
   ```

### Integration Testing

1. **CLI Agent Test**
   ```bash
   # Test with a simple query
   echo "Show me all employees" | python agent/run_agent.py --adapter <model-id>
   ```

2. **Web Demo Test**
   ```bash
   python demo/app.py &
   curl -X POST "http://localhost:7860/api/predict" \
        -F "data=Who works in Engineering?"
   ```

### Validation Steps

1. **Database Schema Validation**
   ```bash
   sqlite3 data/dummy_database.db ".schema employees"
   ```

2. **Model Response Validation**
   - Verify generated SQL is syntactically correct
   - Check that results match expected output
   - Ensure error handling works for invalid queries

## ğŸ’» Development

### Training the Model

1. **Prepare training data**
   ```bash
   python scripts/train.py --data_path <path-to-training-data>
   ```

2. **Fine-tune with QLoRA**
   ```bash
   python scripts/train.py \
       --base_model Qwen/Qwen2.5-1.5B-Instruct \
       --output_dir ./trained_model \
       --batch_size 4 \
       --learning_rate 2e-4
   ```

### Evaluation

1. **Model evaluation**
   ```bash
   python scripts/evaluate.py \
       --model_path <trained-model-path> \
       --test_data <test-dataset>
   ```

2. **Performance metrics**
   - SQL accuracy
   - Execution success rate
   - Response latency

### Adding New Features

1. **Database Schema Extensions**
   - Modify `scripts/setup_db.py` for new tables
   - Update schema context in agent code

2. **Model Improvements**
   - Fine-tune with additional data
   - Experiment with different base models
   - Optimize prompt templates

## ğŸ”¬ Technical Details

### Model Architecture

- **Base Model**: Qwen 2.5-1.5B-Instruct
- **Fine-tuning Method**: QLoRA (Quantized Low-Rank Adaptation)
- **Training Data**: Text-to-SQL pairs with database schemas
- **Optimization**: 4-bit quantization with LoRA adapters

### Performance Characteristics

| Metric | Value |
|--------|-------|
| Model Size | ~1.5B parameters |
| Memory Usage | 6GB (4-bit quantized) |
| Inference Speed | ~2-3 seconds per query |
| Accuracy | 85%+ on test queries |

### Limitations

- **Database Support**: Currently SQLite only
- **Schema Context**: Limited to provided schema information
- **Complex Queries**: May struggle with very complex JOIN operations
- **Training Data**: Performance depends on training data quality

### Error Handling

- **SQL Syntax Errors**: Graceful error messages with query feedback
- **Database Connection Issues**: Automatic retry mechanisms
- **Model Loading Failures**: Fallback to base model
- **Invalid Queries**: Clear error descriptions for users

## ğŸ¤ Contributing

### Development Setup

1. Fork the repository
2. Create a feature branch
3. Install development dependencies
4. Make your changes
5. Add tests for new functionality
6. Submit a pull request

### Code Style

- **Python**: Follow PEP 8 style guidelines
- **Documentation**: Use docstrings for all functions
- **Testing**: Include unit tests for new features
- **Commits**: Use conventional commit messages

### Adding New Features

1. **Database Support**: Extend to PostgreSQL, MySQL
2. **Model Improvements**: Experiment with larger models
3. **Interface Enhancements**: Add API endpoints, streaming responses
4. **Security**: Implement query sanitization, access controls

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Qwen Team**: For the excellent base model
- **Hugging Face**: For transformers library and model hub
- **Community**: For feedback and contributions

---

**Note**: This agent is designed for educational and development purposes. For production use, implement additional security measures, error handling, and monitoring.
